{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbe4fLc9zY1s"
      },
      "source": [
        "# Large-scale multi-label text classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ldq5tx6zY1v"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XADqkhPmzY1w"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ocsr9ezvzY1w"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from ast import literal_eval\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uCSS_4OzY1y"
      },
      "source": [
        "## Perform exploratory data analysis\n",
        "\n",
        "In this section, we first load the dataset into a `pandas` dataframe and then perform\n",
        "some basic exploratory data analysis (EDA)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "HH1gjUjlzY1y",
        "outputId": "7c6cb049-b099-46c9-af2e-d77d1e5025c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              titles  \\\n",
              "0  Survey on Semantic Stereo Matching / Semantic ...   \n",
              "1  FUTURE-AI: Guiding Principles and Consensus Re...   \n",
              "2  Enforcing Mutual Consistency of Hard Regions f...   \n",
              "3  Parameter Decoupling Strategy for Semi-supervi...   \n",
              "4  Background-Foreground Segmentation for Interio...   \n",
              "\n",
              "                                           summaries  \\\n",
              "0  Stereo matching is one of the widely used tech...   \n",
              "1  The recent advancements in artificial intellig...   \n",
              "2  In this paper, we proposed a novel mutual cons...   \n",
              "3  Consistency training has proven to be an advan...   \n",
              "4  To ensure safety in automated driving, the cor...   \n",
              "\n",
              "                         terms  \n",
              "0           ['cs.CV', 'cs.LG']  \n",
              "1  ['cs.CV', 'cs.AI', 'cs.LG']  \n",
              "2           ['cs.CV', 'cs.AI']  \n",
              "3                    ['cs.CV']  \n",
              "4           ['cs.CV', 'cs.LG']  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d153f9b4-9531-416e-9a15-8098c9f85404\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>titles</th>\n",
              "      <th>summaries</th>\n",
              "      <th>terms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Survey on Semantic Stereo Matching / Semantic ...</td>\n",
              "      <td>Stereo matching is one of the widely used tech...</td>\n",
              "      <td>['cs.CV', 'cs.LG']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FUTURE-AI: Guiding Principles and Consensus Re...</td>\n",
              "      <td>The recent advancements in artificial intellig...</td>\n",
              "      <td>['cs.CV', 'cs.AI', 'cs.LG']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Enforcing Mutual Consistency of Hard Regions f...</td>\n",
              "      <td>In this paper, we proposed a novel mutual cons...</td>\n",
              "      <td>['cs.CV', 'cs.AI']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Parameter Decoupling Strategy for Semi-supervi...</td>\n",
              "      <td>Consistency training has proven to be an advan...</td>\n",
              "      <td>['cs.CV']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Background-Foreground Segmentation for Interio...</td>\n",
              "      <td>To ensure safety in automated driving, the cor...</td>\n",
              "      <td>['cs.CV', 'cs.LG']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d153f9b4-9531-416e-9a15-8098c9f85404')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d153f9b4-9531-416e-9a15-8098c9f85404 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d153f9b4-9531-416e-9a15-8098c9f85404');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f1c07a66-db1e-45a4-8417-2d72de952f2b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f1c07a66-db1e-45a4-8417-2d72de952f2b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f1c07a66-db1e-45a4-8417-2d72de952f2b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "arxiv_data",
              "summary": "{\n  \"name\": \"arxiv_data\",\n  \"rows\": 51774,\n  \"fields\": [\n    {\n      \"column\": \"titles\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 38972,\n        \"samples\": [\n          \"Sum-Product-Transform Networks: Exploiting Symmetries using Invertible Transformations\",\n          \"A Primal-Dual Subgradient Approachfor Fair Meta Learning\",\n          \"Adversarial Multi-Source Transfer Learning in Healthcare: Application to Glucose Prediction for Diabetic People\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summaries\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 38979,\n        \"samples\": [\n          \"Continual learning (CL) is a setting in which an agent has to learn from an\\nincoming stream of data during its entire lifetime. Although major advances\\nhave been made in the field, one recurring problem which remains unsolved is\\nthat of Catastrophic Forgetting (CF). While the issue has been extensively\\nstudied empirically, little attention has been paid from a theoretical angle.\\nIn this paper, we show that the impact of CF increases as two tasks\\nincreasingly align. We introduce a measure of task similarity called the NTK\\noverlap matrix which is at the core of CF. We analyze common projected gradient\\nalgorithms and demonstrate how they mitigate forgetting. Then, we propose a\\nvariant of Orthogonal Gradient Descent (OGD) which leverages structure of the\\ndata through Principal Component Analysis (PCA). Experiments support our\\ntheoretical findings and show how our method can help reduce CF on classical CL\\ndatasets.\",\n          \"Few-shot learning is a challenging task since only few instances are given\\nfor recognizing an unseen class. One way to alleviate this problem is to\\nacquire a strong inductive bias via meta-learning on similar tasks. In this\\npaper, we show that such inductive bias can be learned from a flat collection\\nof unlabeled images, and instantiated as transferable representations among\\nseen and unseen classes. Specifically, we propose a novel part-based\\nself-supervised representation learning scheme to learn transferable\\nrepresentations by maximizing the similarity of an image to its discriminative\\npart. To mitigate the overfitting in few-shot classification caused by data\\nscarcity, we further propose a part augmentation strategy by retrieving extra\\nimages from a base dataset. We conduct systematic studies on miniImageNet and\\ntieredImageNet benchmarks. Remarkably, our method yields impressive results,\\noutperforming the previous best unsupervised methods by 7.74% and 9.24% under\\n5-way 1-shot and 5-way 5-shot settings, which are comparable with\\nstate-of-the-art supervised methods.\",\n          \"Surgical instrument segmentation is extremely important for computer-assisted\\nsurgery. Different from common object segmentation, it is more challenging due\\nto the large illumination and scale variation caused by the special surgical\\nscenes. In this paper, we propose a novel bilinear attention network with\\nadaptive receptive field to solve these two challenges. For the illumination\\nvariation, the bilinear attention module can capture second-order statistics to\\nencode global contexts and semantic dependencies between local pixels. With\\nthem, semantic features in challenging areas can be inferred from their\\nneighbors and the distinction of various semantics can be boosted. For the\\nscale variation, our adaptive receptive field module aggregates multi-scale\\nfeatures and automatically fuses them with different weights. Specifically, it\\nencodes the semantic relationship between channels to emphasize feature maps\\nwith appropriate scales, changing the receptive field of subsequent\\nconvolutions. The proposed network achieves the best performance 97.47% mean\\nIOU on Cata7 and comes first place on EndoVis 2017 by 10.10% IOU overtaking\\nsecond-ranking method.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"terms\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3157,\n        \"samples\": [\n          \"['cs.LG', 'cs.CE', 'q-fin.ST', 'stat.ML']\",\n          \"['cs.LG', 'physics.comp-ph', 'physics.flu-dyn']\",\n          \"['cs.LG', 'cs.CV', 'math.AT']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "arxiv_data = pd.read_csv(\"/content/arxiv_data.csv\")\n",
        "arxiv_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9HNV_MYzY1y",
        "outputId": "3a361444-3653-4ca2-c519-3400b0edb85a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 51774 rows in the dataset.\n"
          ]
        }
      ],
      "source": [
        "print(f\"There are {len(arxiv_data)} rows in the dataset.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_y15biUzY1z",
        "outputId": "ad8ca330-c957-4342-e764-5a758c9aaf9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 12802 duplicate titles.\n"
          ]
        }
      ],
      "source": [
        "total_duplicate_titles = sum(arxiv_data[\"titles\"].duplicated())\n",
        "print(f\"There are {total_duplicate_titles} duplicate titles.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AKNc0VDzY1z"
      },
      "source": [
        "Before proceeding further, drop these entries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gPo7-YZzY10",
        "outputId": "61932c30-6a65-4b6a-b70b-236b539fb4f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 38972 rows in the deduplicated dataset.\n",
            "2321\n",
            "3157\n"
          ]
        }
      ],
      "source": [
        "arxiv_data = arxiv_data[~arxiv_data[\"titles\"].duplicated()]\n",
        "print(f\"There are {len(arxiv_data)} rows in the deduplicated dataset.\")\n",
        "\n",
        "# There are some terms with occurrence as low as 1.\n",
        "print(sum(arxiv_data[\"terms\"].value_counts() == 1))\n",
        "\n",
        "# How many unique terms?\n",
        "print(arxiv_data[\"terms\"].nunique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYD8TqLEzY11",
        "outputId": "01d91a2d-e640-4acc-d81e-4c439561da6f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36651, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Filtering the rare terms.\n",
        "arxiv_data_filtered = arxiv_data.groupby(\"terms\").filter(lambda x: len(x) > 1)\n",
        "arxiv_data_filtered.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQpWa3lbzY11"
      },
      "source": [
        "## Convert the string labels to lists of strings\n",
        "\n",
        "The initial labels are represented as raw strings. Here we make them `List[str]` for a\n",
        "more compact representation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVTahtTpzY11",
        "outputId": "269f476c-2152-40f3-cfe8-3483ad6f22f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list(['cs.CV', 'cs.LG']), list(['cs.CV', 'cs.AI', 'cs.LG']),\n",
              "       list(['cs.CV', 'cs.AI']), list(['cs.CV']),\n",
              "       list(['cs.CV', 'cs.LG'])], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "arxiv_data_filtered[\"terms\"] = arxiv_data_filtered[\"terms\"].apply(\n",
        "    lambda x: literal_eval(x)\n",
        ")\n",
        "arxiv_data_filtered[\"terms\"].values[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iy7YyTczY12"
      },
      "source": [
        "## Use stratified splits because of class imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnMc_FBNzY12",
        "outputId": "692e810e-9f1c-4bee-fc42-63b56f276aa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows in training set: 32985\n",
            "Number of rows in validation set: 1833\n",
            "Number of rows in test set: 1833\n"
          ]
        }
      ],
      "source": [
        "test_split = 0.1\n",
        "\n",
        "# Initial train and test split.\n",
        "train_df, test_df = train_test_split(\n",
        "    arxiv_data_filtered,\n",
        "    test_size=test_split,\n",
        "    stratify=arxiv_data_filtered[\"terms\"].values,\n",
        ")\n",
        "\n",
        "# Splitting the test set further into validation\n",
        "# and new test sets.\n",
        "val_df = test_df.sample(frac=0.5)\n",
        "test_df.drop(val_df.index, inplace=True)\n",
        "\n",
        "print(f\"Number of rows in training set: {len(train_df)}\")\n",
        "print(f\"Number of rows in validation set: {len(val_df)}\")\n",
        "print(f\"Number of rows in test set: {len(test_df)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MawwDMB5zY13"
      },
      "source": [
        "## Multi-label binarization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhqGFwt0zY13",
        "outputId": "d2e70306-541a-4354-8e07-6c663ecd7c1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary:\n",
            "\n",
            "['[UNK]', 'cs.CV', 'cs.LG', 'stat.ML', 'cs.AI', 'eess.IV', 'cs.RO', 'cs.CL', 'cs.NE', 'cs.CR', 'math.OC', 'eess.SP', 'cs.GR', 'cs.SI', 'cs.MM', 'cs.SY', 'cs.IR', 'cs.MA', 'eess.SY', 'cs.HC', 'math.IT', 'cs.IT', 'cs.DC', 'cs.CY', 'stat.AP', 'stat.TH', 'math.ST', 'stat.ME', 'eess.AS', 'cs.SD', 'q-bio.QM', 'q-bio.NC', 'cs.DS', 'cs.GT', 'cs.SE', 'cs.NI', 'cs.CG', 'I.2.6', 'stat.CO', 'math.NA', 'cs.NA', 'physics.chem-ph', 'cs.DB', 'q-bio.BM', 'cs.LO', 'cond-mat.dis-nn', '68T45', 'math.PR', 'cs.PL', 'physics.comp-ph', 'cs.CE', 'cs.AR', 'I.2.10', 'q-fin.ST', 'cond-mat.stat-mech', 'math.DS', '68T05', 'quant-ph', 'cs.CC', 'I.4.6', 'physics.data-an', 'physics.soc-ph', 'physics.ao-ph', 'econ.EM', 'cs.DM', 'q-bio.GN', 'physics.med-ph', 'astro-ph.IM', 'I.4.8', 'math.AT', 'cs.PF', 'cs.FL', 'I.4', 'q-fin.TR', 'I.5.4', 'I.2', '68U10', 'physics.optics', 'physics.geo-ph', 'hep-ex', '68T10', 'cond-mat.mtrl-sci', 'physics.flu-dyn', 'math.AP', 'I.4; I.5', 'I.4.9', 'I.2.6; I.2.8', '68T01', '65D19', 'q-fin.CP', 'nlin.CD', 'math.CO', 'cs.MS', 'I.2.6; I.5.1', 'I.2.10; I.4; I.5', 'I.2.0; I.2.6', '68T07', 'cs.SC', 'cs.ET', 'K.3.2', 'I.2.8', 'I.2.10; I.4.8', '68U01', '68T30', '68', 'q-fin.GN', 'q-fin.EC', 'q-bio.MN', 'econ.GN', 'I.4.9; I.5.4', 'I.4.5', 'I.2; I.5', 'I.2; I.4; I.5', 'I.2.6; I.2.7', '68T99', '68Q32', '62H30', 'q-fin.RM', 'q-fin.PM', 'q-bio.TO', 'q-bio.OT', 'physics.bio-ph', 'nlin.AO', 'math.LO', 'math.FA', 'hep-ph', 'cond-mat.soft', 'I.4.6; I.4.8', 'I.4.4', 'I.4.3', 'I.4.0', 'I.2; J.2', 'I.2; I.2.6; I.2.7', 'I.2.7', 'I.2.6; I.5.4', 'I.2.6; I.2.9', 'I.2.6; I.2.7; H.3.1; H.3.3', 'I.2.6; I.2.10', 'I.2.6, I.5.4', 'I.2.1; J.3', 'I.2.10; I.5.1; I.4.8', 'I.2.10; I.4.8; I.5.4', 'I.2.10; I.2.6', 'I.2.1', 'H.3.1; I.2.6; I.2.7', 'H.3.1; H.3.3; I.2.6; I.2.7', 'G.3', 'F.2.2; I.2.7', 'E.5; E.4; E.2; H.1.1; F.1.1; F.1.3', '68Txx', '62H99', '62H35', '14J60 (Primary) 14F05, 14J26 (Secondary)']\n"
          ]
        }
      ],
      "source": [
        "terms = tf.ragged.constant(train_df[\"terms\"].values)\n",
        "lookup = tf.keras.layers.StringLookup(output_mode=\"multi_hot\")\n",
        "lookup.adapt(terms)\n",
        "vocab = lookup.get_vocabulary()\n",
        "\n",
        "\n",
        "def invert_multi_hot(encoded_labels):\n",
        "    \"\"\"Reverse a single multi-hot encoded label to a tuple of vocab terms.\"\"\"\n",
        "    hot_indices = np.argwhere(encoded_labels == 1.0)[..., 0]\n",
        "    return np.take(vocab, hot_indices)\n",
        "\n",
        "\n",
        "print(\"Vocabulary:\\n\")\n",
        "print(vocab)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlS6pglfzY13",
        "outputId": "6c737471-ec71-4795-f866-f9d9883073ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original label: ['cs.CV']\n",
            "Label-binarized representation: [[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "sample_label = train_df[\"terms\"].iloc[0]\n",
        "print(f\"Original label: {sample_label}\")\n",
        "\n",
        "label_binarized = lookup([sample_label])\n",
        "print(f\"Label-binarized representation: {label_binarized}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIjdqs91zY14"
      },
      "source": [
        "## Data preprocessing and `tf.data.Dataset` objects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "43ay6MW-zY14",
        "outputId": "e179cb5a-934d-41a9-a2c7-6c04ddd7b97a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    32985.000000\n",
              "mean       156.605548\n",
              "std         41.586629\n",
              "min          5.000000\n",
              "25%        128.000000\n",
              "50%        154.000000\n",
              "75%        183.000000\n",
              "max        462.000000\n",
              "Name: summaries, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>summaries</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>32985.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>156.605548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>41.586629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>128.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>154.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>183.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>462.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "train_df[\"summaries\"].apply(lambda x: len(x.split(\" \"))).describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "LPGg9LbuzY15"
      },
      "outputs": [],
      "source": [
        "max_seqlen = 150\n",
        "batch_size = 128\n",
        "padding_token = \"<pad>\"\n",
        "auto = tf.data.AUTOTUNE\n",
        "\n",
        "\n",
        "def make_dataset(dataframe, is_train=True):\n",
        "    labels = tf.ragged.constant(dataframe[\"terms\"].values)\n",
        "    label_binarized = lookup(labels).numpy()\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(\n",
        "        (dataframe[\"summaries\"].values, label_binarized)\n",
        "    )\n",
        "    dataset = dataset.shuffle(batch_size * 10) if is_train else dataset\n",
        "    return dataset.batch(batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "q-yhEMGUzY15"
      },
      "outputs": [],
      "source": [
        "train_dataset = make_dataset(train_df, is_train=True)\n",
        "validation_dataset = make_dataset(val_df, is_train=False)\n",
        "test_dataset = make_dataset(test_df, is_train=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuizkTUBzY16"
      },
      "source": [
        "## Dataset preview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heEwqL5-zY16",
        "outputId": "bbf2b7ef-31cf-4f45-fb71-a5f0a9719589"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Abstract: b'We present an effective post-processing method to reduce the artifacts from\\nsparsely reconstructed cone-beam CT (CBCT) images. The proposed method is based\\non the state-of-the-art, image-to-image generative models with a perceptual\\nloss as regulation. Unlike the traditional CT artifact-reduction approaches,\\nour method is trained in an adversarial fashion that yields more perceptually\\nrealistic outputs while preserving the anatomical structures. To address the\\nstreak artifacts that are inherently local and appear across various scales, we\\nfurther propose a novel discriminator architecture based on feature pyramid\\nnetworks and a differentially modulated focus map to induce the adversarial\\ntraining. Our experimental results show that the proposed method can greatly\\ncorrect the cone-beam artifacts from clinical CBCT images reconstructed using\\n1/3 projections, and outperforms strong baseline methods both quantitatively\\nand qualitatively.'\n",
            "Label(s): ['cs.CV']\n",
            " \n",
            "Abstract: b'Conditional image synthesis aims to create an image according to some\\nmulti-modal guidance in the forms of textual descriptions, reference images,\\nand image blocks to preserve, as well as their combinations. In this paper,\\ninstead of investigating these control signals separately, we propose a new\\ntwo-stage architecture, UFC-BERT, to unify any number of multi-modal controls.\\nIn UFC-BERT, both the diverse control signals and the synthesized image are\\nuniformly represented as a sequence of discrete tokens to be processed by\\nTransformer. Different from existing two-stage autoregressive approaches such\\nas DALL-E and VQGAN, UFC-BERT adopts non-autoregressive generation (NAR) at the\\nsecond stage to enhance the holistic consistency of the synthesized image, to\\nsupport preserving specified image blocks, and to improve the synthesis speed.\\nFurther, we design a progressive algorithm that iteratively improves the\\nnon-autoregressively generated image, with the help of two estimators developed\\nfor evaluating the compliance with the controls and evaluating the fidelity of\\nthe synthesized image, respectively. Extensive experiments on a newly collected\\nlarge-scale clothing dataset M2C-Fashion and a facial dataset Multi-Modal\\nCelebA-HQ verify that UFC-BERT can synthesize high-fidelity images that comply\\nwith flexible multi-modal controls.'\n",
            "Label(s): ['cs.CV']\n",
            " \n",
            "Abstract: b'Graphs can be used to effectively represent complex data structures. Learning\\nthese irregular data in graphs is challenging and still suffers from shallow\\nlearning. Applying deep learning on graphs has recently showed good performance\\nin many applications in social analysis, bioinformatics etc. A message passing\\ngraph convolution network is such a powerful method which has expressive power\\nto learn graph structures. Meanwhile, circRNA is a type of non-coding RNA which\\nplays a critical role in human diseases. Identifying the associations between\\ncircRNAs and diseases is important to diagnosis and treatment of complex\\ndiseases. However, there are limited number of known associations between them\\nand conducting biological experiments to identify new associations is time\\nconsuming and expensive. As a result, there is a need of building efficient and\\nfeasible computation methods to predict potential circRNA-disease associations.\\nIn this paper, we propose a novel graph convolution network framework to learn\\nfeatures from a graph built with multi-source similarity information to predict\\ncircRNA-disease associations. First we use multi-source information of circRNA\\nsimilarity, disease and circRNA Gaussian Interaction Profile (GIP) kernel\\nsimilarity to extract the features using first graph convolution. Then we\\npredict disease associations for each circRNA with second graph convolution.\\nProposed framework with five-fold cross validation on various experiments shows\\npromising results in predicting circRNA-disease association and outperforms\\nother existing methods.'\n",
            "Label(s): ['cs.LG' 'stat.ML']\n",
            " \n",
            "Abstract: b'Myoelectric control is one of the leading areas of research in the field of\\nrobotic prosthetics. We present our research in surface electromyography (sEMG)\\nsignal classification, where our simple and novel attention-based approach now\\nleads the industry, universally beating more complex, state-of-the-art models.\\nOur novel attention-based model achieves benchmark leading results on multiple\\nindustry-standard datasets including 53 finger, wrist, and grasping motions,\\nimproving over both sophisticated signal processing and CNN-based approaches.\\nOur strong results with a straightforward model also indicate that sEMG\\nrepresents a promising avenue for future machine learning research, with\\napplications not only in prosthetics, but also in other important areas, such\\nas diagnosis and prognostication of neurodegenerative diseases, computationally\\nmediated surgeries, and advanced robotic control. We reinforce this suggestion\\nwith extensive ablative studies, demonstrating that a neural network can easily\\nextract higher order spatiotemporal features from noisy sEMG data collected by\\naffordable, consumer-grade sensors.'\n",
            "Label(s): ['cs.LG' 'stat.ML' 'eess.SP']\n",
            " \n",
            "Abstract: b'Deep learning approaches to optical flow estimation have seen rapid progress\\nover the recent years. One common trait of many networks is that they refine an\\ninitial flow estimate either through multiple stages or across the levels of a\\ncoarse-to-fine representation. While leading to more accurate results, the\\ndownside of this is an increased number of parameters. Taking inspiration from\\nboth classical energy minimization approaches as well as residual networks, we\\npropose an iterative residual refinement (IRR) scheme based on weight sharing\\nthat can be combined with several backbone networks. It reduces the number of\\nparameters, improves the accuracy, or even achieves both. Moreover, we show\\nthat integrating occlusion prediction and bi-directional flow estimation into\\nour IRR scheme can further boost the accuracy. Our full network achieves\\nstate-of-the-art results for both optical flow and occlusion estimation across\\nseveral standard datasets.'\n",
            "Label(s): ['cs.CV' 'cs.LG']\n",
            " \n"
          ]
        }
      ],
      "source": [
        "text_batch, label_batch = next(iter(train_dataset))\n",
        "\n",
        "for i, text in enumerate(text_batch[:5]):\n",
        "    label = label_batch[i].numpy()[None, ...]\n",
        "    print(f\"Abstract: {text}\")\n",
        "    print(f\"Label(s): {invert_multi_hot(label[0])}\")\n",
        "    print(\" \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoYKPzcnzY16"
      },
      "source": [
        "## Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMAdgXvdzY16",
        "outputId": "4206ffd8-a713-4c9a-a1b1-a6b9bc30b552"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "153490\n"
          ]
        }
      ],
      "source": [
        "vocabulary = set()\n",
        "train_df[\"summaries\"].str.lower().str.split().apply(vocabulary.update)\n",
        "vocabulary_size = len(vocabulary)\n",
        "print(vocabulary_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "PeveqhdxzY17"
      },
      "outputs": [],
      "source": [
        "text_vectorizer = layers.TextVectorization(\n",
        "    max_tokens=vocabulary_size, ngrams=2, output_mode=\"tf_idf\"\n",
        ")\n",
        "\n",
        "# `TextVectorization` layer needs to be adapted as per the vocabulary from our\n",
        "# training set.\n",
        "with tf.device(\"/CPU:0\"):\n",
        "    text_vectorizer.adapt(train_dataset.map(lambda text, label: text))\n",
        "\n",
        "train_dataset = train_dataset.map(\n",
        "    lambda text, label: (text_vectorizer(text), label), num_parallel_calls=auto\n",
        ").prefetch(auto)\n",
        "validation_dataset = validation_dataset.map(\n",
        "    lambda text, label: (text_vectorizer(text), label), num_parallel_calls=auto\n",
        ").prefetch(auto)\n",
        "test_dataset = test_dataset.map(\n",
        "    lambda text, label: (text_vectorizer(text), label), num_parallel_calls=auto\n",
        ").prefetch(auto)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "..\\examples\\nlp\\multi_label_classification",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}